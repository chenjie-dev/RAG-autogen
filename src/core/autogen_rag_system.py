"""
åŸºäºæ™ºèƒ½ä½“åä½œçš„RAGé—®ç­”ç³»ç»Ÿ
====================================

åŠŸèƒ½ç‰¹æ€§:
- å¤šæ™ºèƒ½ä½“åä½œï¼šæ£€ç´¢æ™ºèƒ½ä½“ã€åˆ†ææ™ºèƒ½ä½“ã€å›ç­”æ™ºèƒ½ä½“
- æ™ºèƒ½ä½“é—´é€šä¿¡ï¼šé€šè¿‡æ¶ˆæ¯ä¼ é€’è¿›è¡Œåä½œ
- è§’è‰²åˆ†å·¥ï¼šæ¯ä¸ªæ™ºèƒ½ä½“è´Ÿè´£ç‰¹å®šä»»åŠ¡
- å¯æ‰©å±•æ€§ï¼šæ˜“äºæ·»åŠ æ–°çš„æ™ºèƒ½ä½“è§’è‰²
- å¹¶å‘å¤„ç†ï¼šæ”¯æŒå¤šä¸ªæ™ºèƒ½ä½“å¹¶è¡Œå·¥ä½œ
- çˆ¶é¡µé¢æ£€ç´¢ï¼šæ”¯æŒè¿”å›æ–‡æ¡£çš„å…·ä½“é¡µé¢ä¿¡æ¯

æ™ºèƒ½ä½“æ¶æ„:
1. RetrievalAgent: æ£€ç´¢æ™ºèƒ½ä½“ï¼Œè´Ÿè´£æ–‡æ¡£æ£€ç´¢
2. AnalysisAgent: åˆ†ææ™ºèƒ½ä½“ï¼Œè´Ÿè´£å†…å®¹åˆ†æ
3. AnswerAgent: å›ç­”æ™ºèƒ½ä½“ï¼Œè´Ÿè´£ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
4. CoordinatorAgent: åè°ƒæ™ºèƒ½ä½“ï¼Œç®¡ç†æ•´ä¸ªæµç¨‹

ä½œè€…: RAGç³»ç»Ÿå¼€å‘å›¢é˜Ÿ
ç‰ˆæœ¬: 2.1.0
æ›´æ–°æ—¥æœŸ: 2024
"""

import os
import json
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
import ollama
from dotenv import load_dotenv

# å¯¼å…¥ç°æœ‰æ¨¡å—
from src.processors.document_processor import DocumentProcessor
from src.utils.text_utils import TextUtils
from src.utils.vector_store import VectorStore
from src.utils.ui_utils import print_info, print_warning, print_success, print_error
from src.utils.logger import logger

# å¯¼å…¥é…ç½®
from config.settings import OLLAMA_BASE_URL, OLLAMA_MODEL

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class Agent:
    """åŸºç¡€æ™ºèƒ½ä½“ç±»"""
    
    def __init__(self, name: str, role: str, system_prompt: str):
        self.name = name
        self.role = role
        self.system_prompt = system_prompt
        self.client = ollama.Client(host=OLLAMA_BASE_URL)
    
    def process(self, message: str, context: str = "") -> str:
        """å¤„ç†æ¶ˆæ¯å¹¶è¿”å›å›å¤"""
        logger.info(f"ğŸ¤– {self.name} å¼€å§‹å¤„ç†æ¶ˆæ¯...")
        logger.info(f"ğŸ“ æ¶ˆæ¯å†…å®¹: {message[:100]}...")
        logger.info(f"ğŸ“‹ ä¸Šä¸‹æ–‡é•¿åº¦: {len(context)} å­—ç¬¦")
        
        try:
            prompt = f"{self.system_prompt}\n\nä¸Šä¸‹æ–‡ä¿¡æ¯:\n{context}\n\nç”¨æˆ·æ¶ˆæ¯:\n{message}\n\nè¯·ä»¥{self.role}çš„èº«ä»½å›å¤:"
            
            logger.info(f"ğŸ”„ {self.name} è°ƒç”¨Ollama API...")
            response = self.client.chat(
                model=OLLAMA_MODEL,
                messages=[{"role": "user", "content": prompt}]
            )
            
            result = response['message']['content']
            logger.info(f"âœ… {self.name} å¤„ç†å®Œæˆï¼Œç»“æœé•¿åº¦: {len(result)} å­—ç¬¦")
            logger.info(f"ğŸ“„ {self.name} ç»“æœé¢„è§ˆ: {result[:100]}...")
            
            return result
        except Exception as e:
            logger.error(f"âŒ {self.name} å¤„ç†å¤±è´¥: {str(e)}")
            print_error(f"{self.name} å¤„ç†å¤±è´¥: {str(e)}")
            return f"å¤„ç†å¤±è´¥: {str(e)}"

class RetrievalAgent(Agent):
    """æ£€ç´¢æ™ºèƒ½ä½“"""
    
    def __init__(self):
        system_prompt = """ä½ æ˜¯æ£€ç´¢æ™ºèƒ½ä½“ï¼Œä¸“é—¨è´Ÿè´£ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚

ä½ çš„èŒè´£ï¼š
1. ç†è§£ç”¨æˆ·é—®é¢˜çš„æ ¸å¿ƒéœ€æ±‚
2. ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢æœ€ç›¸å…³çš„ä¿¡æ¯
3. ç¡®ä¿æ£€ç´¢ç»“æœçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
4. è¿‡æ»¤æ— å…³æˆ–ä½è´¨é‡çš„ä¿¡æ¯
5. ä¸ºåç»­åˆ†ææä¾›é«˜è´¨é‡çš„æ£€ç´¢ç»“æœ
6. è®°å½•æ¯ä¸ªç‰‡æ®µçš„æ¥æºä¿¡æ¯

æ£€ç´¢è¦æ±‚ï¼š
- æ£€ç´¢ç»“æœè¦å…¨é¢è¦†ç›–é—®é¢˜æ¶‰åŠçš„å„ä¸ªæ–¹é¢
- ä¼˜å…ˆé€‰æ‹©é«˜è´¨é‡ã€æƒå¨çš„ä¿¡æ¯æº
- ç¡®ä¿ä¿¡æ¯çš„æ—¶æ•ˆæ€§å’Œå‡†ç¡®æ€§
- é¿å…é‡å¤æˆ–å†—ä½™çš„ä¿¡æ¯
- æ¯ä¸ªç‰‡æ®µçš„æ¥æºä¿¡æ¯
- æ£€ç´¢ç»“æœè¦ä¾¿äºåç»­å¤„ç†å’Œåˆ†æ"""
        
        super().__init__("retrieval_agent", "æ£€ç´¢æ™ºèƒ½ä½“", system_prompt)

class AnalysisAgent(Agent):
    """åˆ†ææ™ºèƒ½ä½“"""
    
    def __init__(self):
        system_prompt = """ä½ æ˜¯åˆ†ææ™ºèƒ½ä½“ï¼Œä¸“é—¨è´Ÿè´£åˆ†ææ£€ç´¢åˆ°çš„ä¿¡æ¯ã€‚

ä½ çš„èŒè´£ï¼š
1. æ·±å…¥åˆ†ææ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹
2. è¯†åˆ«å…³é”®ä¿¡æ¯å’Œé‡è¦è§‚ç‚¹
3. è¯„ä¼°ä¿¡æ¯çš„å¯ä¿¡åº¦å’Œæ—¶æ•ˆæ€§
4. å‘ç°ä¿¡æ¯é—´çš„å…³è”å’ŒçŸ›ç›¾
5. ä¸ºå›ç­”æ™ºèƒ½ä½“æä¾›åˆ†æç»“æœ
6. éªŒè¯ä¿¡æ¯æ¥æºçš„å‡†ç¡®æ€§

åˆ†æç»´åº¦ï¼š
- å†…å®¹å‡†ç¡®æ€§
- ä¿¡æ¯å®Œæ•´æ€§
- é€»è¾‘ä¸€è‡´æ€§
- æ—¶æ•ˆæ€§
- å¯ä¿¡åº¦
- ä¿¡æ¯æ¥æºå‡†ç¡®æ€§

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- ä½¿ç”¨markdownæ ¼å¼
- æ®µè½ä¹‹é—´ç”¨ç©ºè¡Œåˆ†éš”
- é‡è¦ä¿¡æ¯ç”¨**ç²—ä½“**æ ‡è®°
- åˆ—è¡¨ä½¿ç”¨- æ ¼å¼
- å…³é”®ä¿¡æ¯æ‘˜è¦
- ä¿¡æ¯è´¨é‡è¯„ä¼°
- æ½œåœ¨é—®é¢˜æˆ–çŸ›ç›¾
- å»ºè®®çš„å›ç­”æ–¹å‘
- ä¿¡æ¯æ¥æºéªŒè¯"""
        
        super().__init__("analysis_agent", "åˆ†ææ™ºèƒ½ä½“", system_prompt)

class AnswerAgent(Agent):
    """å›ç­”æ™ºèƒ½ä½“"""
    
    def __init__(self):
        system_prompt = """ä½ æ˜¯å›ç­”æ™ºèƒ½ä½“ï¼Œä¸“é—¨è´Ÿè´£ç”Ÿæˆæœ€ç»ˆçš„ç”¨æˆ·ç­”æ¡ˆã€‚

ä½ çš„èŒè´£ï¼š
1. åŸºäºæ£€ç´¢å’Œåˆ†æç»“æœç”Ÿæˆå‡†ç¡®ã€å®Œæ•´çš„ç­”æ¡ˆ
2. ç¡®ä¿ç­”æ¡ˆçš„é€»è¾‘æ€§å’Œå¯è¯»æ€§
3. ä½¿ç”¨åˆé€‚çš„è¯­è¨€é£æ ¼å’Œè¡¨è¾¾æ–¹å¼
4. å¤„ç†å¤æ‚é—®é¢˜å’Œå¤šè§’åº¦åˆ†æ
5. æ ‡æ³¨ä¿¡æ¯æ¥æº
6. ç¡®ä¿ç­”æ¡ˆçš„å¯ä¿¡åº¦å’Œæƒå¨æ€§

å›ç­”è¦æ±‚ï¼š
- ç­”æ¡ˆè¦å‡†ç¡®ã€å®Œæ•´ã€æœ‰æ¡ç†
- ä½¿ç”¨markdownæ ¼å¼ï¼Œç»“æ„æ¸…æ™°
- é‡è¦ä¿¡æ¯ç”¨**ç²—ä½“**æ ‡è®°
- åˆ—è¡¨ä½¿ç”¨- æˆ–1. æ ¼å¼
- ä»£ç ç”¨`ä»£ç `æ ¼å¼
- ç”¨ä¸­æ–‡å›ç­”ï¼Œè¯­è¨€è¦è‡ªç„¶æµç•…
- æ ‡æ³¨ä¿¡æ¯æ¥æº"""
        
        super().__init__("answer_agent", "å›ç­”æ™ºèƒ½ä½“", system_prompt)

class CoordinatorAgent(Agent):
    """åè°ƒæ™ºèƒ½ä½“"""
    
    def __init__(self):
        system_prompt = """ä½ æ˜¯åè°ƒæ™ºèƒ½ä½“ï¼Œè´Ÿè´£åè°ƒæ•´ä¸ªæ™ºèƒ½ä½“åä½œæµç¨‹ã€‚

ä½ çš„èŒè´£ï¼š
1. æ¥æ”¶ç”¨æˆ·é—®é¢˜å¹¶åˆ†å‘ç»™ç›¸åº”æ™ºèƒ½ä½“
2. åè°ƒæ™ºèƒ½ä½“é—´çš„åä½œ
3. ç¡®ä¿æµç¨‹çš„å®Œæ•´æ€§å’Œè´¨é‡
4. å¤„ç†å¼‚å¸¸æƒ…å†µå’Œé”™è¯¯
5. æ•´åˆæœ€ç»ˆç»“æœ
6. éªŒè¯ä¿¡æ¯æ¥æºçš„å‡†ç¡®æ€§

å·¥ä½œæµç¨‹ï¼š
1. æ¥æ”¶ç”¨æˆ·é—®é¢˜
2. å¯åŠ¨æ£€ç´¢æ™ºèƒ½ä½“
3. å¯åŠ¨åˆ†ææ™ºèƒ½ä½“
4. å¯åŠ¨å›ç­”æ™ºèƒ½ä½“
5. æ•´åˆå¹¶è¿”å›æœ€ç»ˆç­”æ¡ˆ

æ³¨æ„äº‹é¡¹ï¼š
- ç¡®ä¿æ¯ä¸ªæ™ºèƒ½ä½“éƒ½å®Œæˆå…¶ä»»åŠ¡
- å¤„ç†æ™ºèƒ½ä½“é—´çš„ä¾èµ–å…³ç³»
- ç›‘æ§æ•´ä¸ªæµç¨‹çš„è¿›åº¦
- å¤„ç†å¼‚å¸¸å’Œé”™è¯¯æƒ…å†µ
- éªŒè¯ä¿¡æ¯æ¥æºçš„å‡†ç¡®æ€§"""
        
        super().__init__("coordinator", "åè°ƒæ™ºèƒ½ä½“", system_prompt)

class AutoGenRAGSystem:
    """åŸºäºæ™ºèƒ½ä½“åä½œçš„RAGé—®ç­”ç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ™ºèƒ½ä½“ç³»ç»Ÿ"""
        logger.info("=" * 60)
        logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–AutoGenæ™ºèƒ½ä½“åä½œç³»ç»Ÿ...")
        print_info("æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½ä½“åä½œç³»ç»Ÿ...")
        
        # åˆå§‹åŒ–åŸºç¡€ç»„ä»¶
        logger.info("ğŸ“¦ åˆå§‹åŒ–åŸºç¡€ç»„ä»¶...")
        self.vector_store = VectorStore()
        self.text_utils = TextUtils()
        self.doc_processor = DocumentProcessor()
        logger.info("âœ… åŸºç¡€ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
        
        # åˆ›å»ºæ™ºèƒ½ä½“
        logger.info("ğŸ¤– åˆ›å»ºæ™ºèƒ½ä½“...")
        self.retrieval_agent = RetrievalAgent()
        logger.info("  - æ£€ç´¢æ™ºèƒ½ä½“åˆ›å»ºå®Œæˆ")
        self.analysis_agent = AnalysisAgent()
        logger.info("  - åˆ†ææ™ºèƒ½ä½“åˆ›å»ºå®Œæˆ")
        self.answer_agent = AnswerAgent()
        logger.info("  - å›ç­”æ™ºèƒ½ä½“åˆ›å»ºå®Œæˆ")
        self.coordinator = CoordinatorAgent()
        logger.info("  - åè°ƒæ™ºèƒ½ä½“åˆ›å»ºå®Œæˆ")
        
        logger.info("ğŸ‰ AutoGenæ™ºèƒ½ä½“åä½œç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        logger.info("=" * 60)
        print_success("æ™ºèƒ½ä½“åä½œç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def add_document(self, file_path: str):
        """æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        logger.info(f"ğŸ“„ å¼€å§‹å¤„ç†æ–‡æ¡£: {file_path}")
        try:
            print_info(f"æ­£åœ¨å¤„ç†æ–‡æ¡£: {file_path}")
            
            # è·å–æ–‡ä»¶æ‰©å±•å
            file_ext = os.path.splitext(file_path)[1].lower()
            
            if file_ext == '.pdf':
                # ä½¿ç”¨æ–°çš„PDFå¤„ç†æ–¹æ³•ï¼Œä¿æŒé¡µé¢ä¿¡æ¯
                logger.info("ğŸ”§ ä½¿ç”¨PDFé¡µé¢å¤„ç†æ–¹æ³•...")
                processed_data = self.doc_processor.process_pdf_with_pages(file_path)
                
                if not processed_data or not processed_data.get('chunks'):
                    logger.warning(f"âš ï¸ PDFæ–‡æ¡£ {file_path} å¤„ç†ç»“æœä¸ºç©º")
                    print_warning(f"PDFæ–‡æ¡£ {file_path} å¤„ç†ç»“æœä¸ºç©º")
                    return False
                
                # æ·»åŠ å¸¦é¡µé¢ä¿¡æ¯çš„chunksåˆ°å‘é‡æ•°æ®åº“
                logger.info("ğŸ’¾ æ·»åŠ åˆ°å‘é‡å­˜å‚¨...")
                success = self.vector_store.add_texts_with_pages(
                    texts=processed_data['chunks'],
                    source=os.path.basename(file_path)
                )
                
                if success:
                    logger.info(f"âœ… PDFæ–‡æ¡£ {file_path} æ·»åŠ æˆåŠŸï¼Œå…± {len(processed_data['chunks'])} ä¸ªchunksï¼Œ{len(processed_data['pages'])} é¡µ")
                    print_success(f"PDFæ–‡æ¡£ {file_path} æ·»åŠ æˆåŠŸ")
                    return True
                else:
                    logger.error(f"âŒ PDFæ–‡æ¡£ {file_path} æ·»åŠ å¤±è´¥")
                    print_error(f"PDFæ–‡æ¡£ {file_path} æ·»åŠ å¤±è´¥")
                    return False
            else:
                # å¯¹äºéPDFæ–‡ä»¶ï¼Œä½¿ç”¨åŸæœ‰æ–¹æ³•
                logger.info("ğŸ”§ ä½¿ç”¨åŸæœ‰æ–‡æ¡£å¤„ç†æ–¹æ³•...")
                processed_texts = self.doc_processor.process_file(file_path)
                
                if not processed_texts:
                    logger.warning(f"âš ï¸ æ–‡æ¡£ {file_path} å¤„ç†ç»“æœä¸ºç©º")
                    print_warning(f"æ–‡æ¡£ {file_path} å¤„ç†ç»“æœä¸ºç©º")
                    return False
                
                logger.info(f"ğŸ“ æ–‡æ¡£å¤„ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(processed_texts)} ä¸ªæ–‡æœ¬ç‰‡æ®µ")
                
                # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
                logger.info("ğŸ’¾ æ·»åŠ åˆ°å‘é‡å­˜å‚¨...")
                success = self.vector_store.add_texts(
                    texts=processed_texts,
                    source=os.path.basename(file_path)
                )
                
                if success:
                    logger.info(f"âœ… æ–‡æ¡£ {file_path} æ·»åŠ æˆåŠŸ")
                    print_success(f"æ–‡æ¡£ {file_path} æ·»åŠ æˆåŠŸ")
                    return True
                else:
                    logger.error(f"âŒ æ–‡æ¡£ {file_path} æ·»åŠ å¤±è´¥")
                    print_error(f"æ–‡æ¡£ {file_path} æ·»åŠ å¤±è´¥")
                    return False
                
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ–‡æ¡£ {file_path} æ—¶å‡ºé”™: {str(e)}")
            print_error(f"å¤„ç†æ–‡æ¡£ {file_path} æ—¶å‡ºé”™: {str(e)}")
            return False

    def add_knowledge(self, texts: List[str], source: str = "manual_input"):
        """æ·»åŠ çŸ¥è¯†åˆ°çŸ¥è¯†åº“"""
        logger.info(f"ğŸ“š å¼€å§‹æ·»åŠ çŸ¥è¯†ï¼Œæ¥æº: {source}ï¼Œæ•°é‡: {len(texts)} æ¡")
        try:
            print_info(f"æ­£åœ¨æ·»åŠ çŸ¥è¯†ï¼Œæ¥æº: {source}")
            
            # æ·»åŠ åˆ°å‘é‡å­˜å‚¨
            logger.info("ğŸ’¾ æ·»åŠ åˆ°å‘é‡å­˜å‚¨...")
            success = self.vector_store.add_texts(texts=texts, source=source)
            
            if success:
                logger.info(f"âœ… çŸ¥è¯†æ·»åŠ æˆåŠŸï¼Œå…± {len(texts)} æ¡")
                print_success(f"çŸ¥è¯†æ·»åŠ æˆåŠŸï¼Œå…± {len(texts)} æ¡")
                return True
            else:
                logger.error("âŒ çŸ¥è¯†æ·»åŠ å¤±è´¥")
                print_error("çŸ¥è¯†æ·»åŠ å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ çŸ¥è¯†æ—¶å‡ºé”™: {str(e)}")
            print_error(f"æ·»åŠ çŸ¥è¯†æ—¶å‡ºé”™: {str(e)}")
            return False

    def search_similar(self, query_text: str, top_k: int = 20) -> List[Dict]:
        """æœç´¢ç›¸ä¼¼æ–‡æ¡£ï¼Œçˆ¶é¡µé¢æ£€ç´¢é»˜è®¤å¼€å¯"""
        logger.info(f"ğŸ” å¼€å§‹æœç´¢ç›¸ä¼¼æ–‡æ¡£ï¼ŒæŸ¥è¯¢: {query_text[:50]}...ï¼Œtop_k: {top_k}")
        try:
            results = self.vector_store.search_similar(query_text, top_k, return_parent_pages=True)
            logger.info(f"âœ… æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")
            return results
        except Exception as e:
            logger.error(f"âŒ æœç´¢å¤±è´¥: {str(e)}")
            print_error(f"æœç´¢å¤±è´¥: {str(e)}")
            return []

    def search_knowledge_base(self, query: str, top_k: int = 20, use_reranking: bool = True, llm_weight: float = 0.7) -> List[Dict]:
        """æœç´¢çŸ¥è¯†åº“
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            use_reranking: æ˜¯å¦ä½¿ç”¨LLMé‡æ’åº
            llm_weight: LLMé‡æ’åºæƒé‡
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        try:
            logger.info(f"æœç´¢çŸ¥è¯†åº“: {query[:50]}...")
            results = self.vector_store.search_similar(
                query, 
                top_k=top_k, 
                return_parent_pages=True,
                use_reranking=use_reranking,
                llm_weight=llm_weight
            )
            logger.info(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")
            return results
        except Exception as e:
            logger.error(f"æœç´¢çŸ¥è¯†åº“æ—¶å‡ºé”™: {str(e)}")
            return []

    async def answer_question_async(self, question: str, fast_mode: bool = True, use_reranking: bool = True, llm_weight: float = 0.7) -> Dict[str, Any]:
        """å¼‚æ­¥å›ç­”é—®é¢˜ï¼Œçˆ¶é¡µé¢æ£€ç´¢é»˜è®¤å¼€å¯"""
        logger.info(f"ğŸ”„ å¼‚æ­¥å›ç­”é—®é¢˜: {question}")
        try:
            if fast_mode:
                # å¿«é€Ÿæ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨RAGç³»ç»Ÿ
                logger.info("âš¡ ä½¿ç”¨å¿«é€Ÿæ¨¡å¼")
                
                # æœç´¢ç›¸å…³æ–‡æ¡£
                similar_docs = self.search_knowledge_base(
                    question, 
                    top_k=20,
                    use_reranking=use_reranking,
                    llm_weight=llm_weight
                )
                
                if not similar_docs:
                    logger.warning("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
                    return {
                        "answer": "æŠ±æ­‰ï¼Œæˆ‘åœ¨æ–‡æ¡£ä¸­æ²¡æœ‰æ‰¾åˆ°ä¸æ‚¨é—®é¢˜ç›¸å…³çš„ä¿¡æ¯ã€‚",
                        "context": "",
                        "analysis": "",
                        "framework": "AutoGenå¿«é€Ÿæ¨¡å¼",
                        "agents_involved": ["retrieval_agent"],
                        "sources": []
                    }
                
                # æ„å»ºä¸Šä¸‹æ–‡
                context_parts = []
                sources = []
                
                for i, doc in enumerate(similar_docs[:5]):  # åªä½¿ç”¨å‰5ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£
                    context_parts.append(f"æ–‡æ¡£ç‰‡æ®µ {i+1}:\n{doc['text']}")
                    sources.append(doc.get('source', doc.get('document_name', 'æœªçŸ¥æ–‡æ¡£')))
                
                context = "\n\n".join(context_parts)
                sources_text = "ã€".join(list(set(sources)))
                
                # æ„å»ºç”¨æˆ·æç¤ºè¯
                user_prompt = f"""åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œè¯·å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š

æ–‡æ¡£å†…å®¹ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·æä¾›è¯¦ç»†çš„åˆ†æè¿‡ç¨‹å’Œå‡†ç¡®çš„ç­”æ¡ˆã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚

åœ¨å›ç­”æœ«å°¾è¯·æ ‡æ³¨ä¿¡æ¯æ¥æºçš„æ–‡æ¡£åç§°ï¼š{sources_text}"""

                # è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆ
                logger.info("æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...")
                response = self.ollama_client.chat(
                    model='deepseek-r1:14b',
                    messages=[
                        {"role": "system", "content": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆåŠ©æ‰‹ï¼Œä¸“é—¨å›ç­”åŸºäºä¸Šä¼ æ–‡æ¡£çš„é‡‘èç›¸å…³é—®é¢˜ã€‚

ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„æ–‡æ¡£å†…å®¹ï¼Œå‡†ç¡®å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. **ä¸¥æ ¼åŸºäºæ–‡æ¡£å†…å®¹**ï¼šåªä½¿ç”¨æä¾›çš„æ–‡æ¡£å†…å®¹æ¥å›ç­”é—®é¢˜ï¼Œä¸è¦ä½¿ç”¨å¤–éƒ¨çŸ¥è¯†
2. **å‡†ç¡®å¼•ç”¨**ï¼šåœ¨å›ç­”ä¸­æ˜ç¡®æŒ‡å‡ºä¿¡æ¯æ¥æºçš„æ–‡æ¡£åç§°
3. **è¯¦ç»†åˆ†æ**ï¼šæä¾›è¯¦ç»†çš„åˆ†æè¿‡ç¨‹ï¼Œè§£é‡Šå¦‚ä½•ä»æ–‡æ¡£ä¸­å¾—å‡ºç­”æ¡ˆ
4. **è¯šå®å›ç­”**ï¼šå¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜"æ ¹æ®æä¾›çš„æ–‡æ¡£ï¼Œæ— æ³•æ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
5. **ä¿æŒå®¢è§‚**ï¼šä¿æŒå®¢è§‚ä¸­ç«‹çš„åˆ†ææ€åº¦ï¼Œé¿å…ä¸»è§‚åˆ¤æ–­

è¯·ç¡®ä¿ä½ çš„å›ç­”å‡†ç¡®ã€è¯¦ç»†ä¸”åŸºäºæ–‡æ¡£å†…å®¹ã€‚"""},
                        {"role": "user", "content": user_prompt}
                    ]
                )
                
                answer = response['message']['content']
                logger.info("âœ… å¿«é€Ÿæ¨¡å¼å›ç­”å®Œæˆ")
                
                return {
                    "answer": answer,
                    "context": context,
                    "analysis": "å¿«é€Ÿæ¨¡å¼ï¼šç›´æ¥åŸºäºæ£€ç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ",
                    "framework": "AutoGenå¿«é€Ÿæ¨¡å¼",
                    "agents_involved": ["retrieval_agent", "answer_agent"],
                    "sources": list(set(sources))
                }
            else:
                # å®Œæ•´æ¨¡å¼ï¼šä½¿ç”¨å¤šæ™ºèƒ½ä½“åä½œ
                logger.info("ğŸ¤– ä½¿ç”¨å®Œæ•´æ¨¡å¼ - å¤šæ™ºèƒ½ä½“åä½œ")
                
                # åˆ›å»ºç”¨æˆ·ä»£ç†
                user_proxy = autogen.UserProxyAgent(
                    name="user_proxy",
                    human_input_mode="NEVER",
                    max_consecutive_auto_reply=10,
                    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
                    code_execution_config={"work_dir": "workspace"},
                    llm_config=self.llm_config,
                    system_message="ç”¨æˆ·ä»£ç†ï¼Œè´Ÿè´£æ¥æ”¶ç”¨æˆ·é—®é¢˜å¹¶åè°ƒå…¶ä»–æ™ºèƒ½ä½“ã€‚"
                )
                
                # åˆ›å»ºæ£€ç´¢æ™ºèƒ½ä½“
                retrieval_agent = autogen.AssistantAgent(
                    name="retrieval_agent",
                    llm_config=self.llm_config,
                    system_message=f"""ä½ æ˜¯æ£€ç´¢æ™ºèƒ½ä½“ï¼Œè´Ÿè´£ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚

å½“å‰çŸ¥è¯†åº“ç»Ÿè®¡ï¼š
- æ–‡æ¡£æ•°é‡ï¼š{self.get_stats().get('total_documents', 0)}
- å‘é‡æ•°é‡ï¼š{self.get_stats().get('total_vectors', 0)}

æ£€ç´¢ç­–ç•¥ï¼š
1. ä½¿ç”¨è¯­ä¹‰æœç´¢æ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ
2. æ”¯æŒLLMé‡æ’åºï¼ˆæƒé‡ï¼š{llm_weight}ï¼‰
3. è¿”å›æœ€ç›¸å…³çš„5ä¸ªæ–‡æ¡£ç‰‡æ®µä½œä¸ºä¸Šä¸‹æ–‡

è¯·æ ¹æ®ç”¨æˆ·é—®é¢˜ï¼Œä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚"""
                )
                
                # åˆ›å»ºåˆ†ææ™ºèƒ½ä½“
                analysis_agent = autogen.AssistantAgent(
                    name="analysis_agent",
                    llm_config=self.llm_config,
                    system_message="""ä½ æ˜¯åˆ†ææ™ºèƒ½ä½“ï¼Œè´Ÿè´£åˆ†ææ£€ç´¢åˆ°çš„ä¿¡æ¯ã€‚

åˆ†æä»»åŠ¡ï¼š
1. è¯„ä¼°æ£€ç´¢ç»“æœçš„ç›¸å…³æ€§å’Œå¯é æ€§
2. è¯†åˆ«å…³é”®ä¿¡æ¯å’Œæ•°æ®ç‚¹
3. åˆ†æä¿¡æ¯ä¹‹é—´çš„å…³è”æ€§
4. æä¾›åˆ†æè§è§£å’Œå»ºè®®

è¯·å¯¹æ£€ç´¢åˆ°çš„ä¿¡æ¯è¿›è¡Œæ·±å…¥åˆ†æã€‚"""
                )
                
                # åˆ›å»ºå›ç­”æ™ºèƒ½ä½“
                answer_agent = autogen.AssistantAgent(
                    name="answer_agent",
                    llm_config=self.llm_config,
                    system_message="""ä½ æ˜¯å›ç­”æ™ºèƒ½ä½“ï¼Œè´Ÿè´£ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚

å›ç­”è¦æ±‚ï¼š
1. åŸºäºæ£€ç´¢å’Œåˆ†æç»“æœç”Ÿæˆå‡†ç¡®ç­”æ¡ˆ
2. ä½¿ç”¨markdownæ ¼å¼ï¼Œç»“æ„æ¸…æ™°
3. é‡è¦ä¿¡æ¯ç”¨**ç²—ä½“**æ ‡è®°
4. æä¾›è¯¦ç»†çš„åˆ†æè¿‡ç¨‹
5. æ ‡æ³¨ä¿¡æ¯æ¥æº
6. ç”¨ä¸­æ–‡å›ç­”ï¼Œè¯­è¨€è‡ªç„¶æµç•…

è¯·ç”Ÿæˆä¸“ä¸šã€å‡†ç¡®çš„ç­”æ¡ˆã€‚"""
                )
                
                # åˆ›å»ºåè°ƒè€…æ™ºèƒ½ä½“
                coordinator = autogen.AssistantAgent(
                    name="coordinator",
                    llm_config=self.llm_config,
                    system_message="""ä½ æ˜¯åè°ƒè€…æ™ºèƒ½ä½“ï¼Œè´Ÿè´£åè°ƒæ•´ä¸ªé—®ç­”æµç¨‹ã€‚

åè°ƒä»»åŠ¡ï¼š
1. æ¥æ”¶ç”¨æˆ·é—®é¢˜
2. åè°ƒæ£€ç´¢ã€åˆ†æã€å›ç­”ä¸‰ä¸ªæ™ºèƒ½ä½“
3. ç¡®ä¿æµç¨‹é¡ºåˆ©è¿›è¡Œ
4. æ•´åˆæœ€ç»ˆç­”æ¡ˆ

æµç¨‹ï¼š
1. æ£€ç´¢æ™ºèƒ½ä½“ï¼šä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³ä¿¡æ¯
2. åˆ†ææ™ºèƒ½ä½“ï¼šåˆ†ææ£€ç´¢ç»“æœ
3. å›ç­”æ™ºèƒ½ä½“ï¼šç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
4. åè°ƒè€…ï¼šæ•´åˆå¹¶è¿”å›ç»“æœ

è¯·åè°ƒæ•´ä¸ªé—®ç­”æµç¨‹ã€‚"""
                )
                
                # æ‰§è¡Œæ™ºèƒ½ä½“åä½œ
                logger.info("ğŸš€ å¼€å§‹æ™ºèƒ½ä½“åä½œ")
                
                # é¦–å…ˆè¿›è¡Œæ£€ç´¢
                similar_docs = self.search_knowledge_base(
                    question, 
                    top_k=20,
                    use_reranking=use_reranking,
                    llm_weight=llm_weight
                )
                
                if not similar_docs:
                    logger.warning("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
                    return {
                        "answer": "æŠ±æ­‰ï¼Œæˆ‘åœ¨æ–‡æ¡£ä¸­æ²¡æœ‰æ‰¾åˆ°ä¸æ‚¨é—®é¢˜ç›¸å…³çš„ä¿¡æ¯ã€‚",
                        "context": "",
                        "analysis": "",
                        "framework": "AutoGenå®Œæ•´æ¨¡å¼",
                        "agents_involved": ["retrieval_agent", "analysis_agent", "answer_agent", "coordinator"],
                        "sources": []
                    }
                
                # æ„å»ºä¸Šä¸‹æ–‡
                context_parts = []
                sources = []
                
                for i, doc in enumerate(similar_docs[:5]):
                    context_parts.append(f"æ–‡æ¡£ç‰‡æ®µ {i+1}:\n{doc['text']}")
                    sources.append(doc.get('source', doc.get('document_name', 'æœªçŸ¥æ–‡æ¡£')))
                
                context = "\n\n".join(context_parts)
                sources_text = "ã€".join(list(set(sources)))
                
                # æ„å»ºåä½œæç¤ºè¯
                collaboration_prompt = f"""ç”¨æˆ·é—®é¢˜ï¼š{question}

æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯ï¼ˆæ¥æºï¼š{sources_text}ï¼‰ï¼š
{context}

è¯·æŒ‰ç…§ä»¥ä¸‹æµç¨‹åä½œå›ç­”ï¼š

1. æ£€ç´¢æ™ºèƒ½ä½“ï¼šè¯„ä¼°æ£€ç´¢ç»“æœçš„ç›¸å…³æ€§å’Œå®Œæ•´æ€§
2. åˆ†ææ™ºèƒ½ä½“ï¼šæ·±å…¥åˆ†ææ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼Œè¯†åˆ«å…³é”®ç‚¹
3. å›ç­”æ™ºèƒ½ä½“ï¼šåŸºäºåˆ†æç»“æœç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
4. åè°ƒè€…ï¼šæ•´åˆæ‰€æœ‰ç»“æœå¹¶è¿”å›æœ€ç»ˆç­”æ¡ˆ

æœ€ç»ˆç­”æ¡ˆè¦æ±‚ï¼š
- ä½¿ç”¨markdownæ ¼å¼
- ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘ä¸¥å¯†
- é‡è¦ä¿¡æ¯ç”¨**ç²—ä½“**æ ‡è®°
- æä¾›è¯¦ç»†çš„åˆ†æè¿‡ç¨‹
- æ ‡æ³¨ä¿¡æ¯æ¥æº
- ç”¨ä¸­æ–‡å›ç­”ï¼Œè¯­è¨€è‡ªç„¶æµç•…

è¯·å¼€å§‹åä½œã€‚"""
                
                # å¯åŠ¨åä½œ
                chat_result = await user_proxy.a_initiate_chat(
                    coordinator,
                    message=collaboration_prompt
                )
                
                # æå–æœ€ç»ˆç­”æ¡ˆ
                final_answer = ""
                analysis_content = ""
                
                for message in chat_result.chat_history:
                    if message.get("name") == "answer_agent":
                        final_answer = message.get("content", "")
                    elif message.get("name") == "analysis_agent":
                        analysis_content = message.get("content", "")
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç­”æ¡ˆï¼Œä½¿ç”¨æœ€åä¸€ä¸ªæ¶ˆæ¯
                if not final_answer and chat_result.chat_history:
                    final_answer = chat_result.chat_history[-1].get("content", "")
                
                logger.info("âœ… å®Œæ•´æ¨¡å¼åä½œå®Œæˆ")
                
                return {
                    "answer": final_answer,
                    "context": context,
                    "analysis": analysis_content,
                    "framework": "AutoGenå®Œæ•´æ¨¡å¼",
                    "agents_involved": ["retrieval_agent", "analysis_agent", "answer_agent", "coordinator"],
                    "sources": list(set(sources))
                }
                
        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥å›ç­”é—®é¢˜å¤±è´¥: {str(e)}")
            return {
                "answer": f"å›ç­”å¤±è´¥: {str(e)}",
                "context": "",
                "analysis": "",
                "framework": "AutoGen",
                "agents_involved": [],
                "sources": []
            }

    def answer_question(self, question: str, use_reranking: bool = True, llm_weight: float = 0.7) -> str:
        """å›ç­”é—®é¢˜
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            use_reranking: æ˜¯å¦ä½¿ç”¨LLMé‡æ’åº
            llm_weight: LLMé‡æ’åºæƒé‡
            
        Returns:
            ç­”æ¡ˆæ–‡æœ¬
        """
        try:
            logger.info(f"å¼€å§‹å›ç­”é—®é¢˜: {question}")
            
            # æœç´¢ç›¸å…³æ–‡æ¡£
            similar_docs = self.search_knowledge_base(
                question, 
                top_k=20,
                use_reranking=use_reranking,
                llm_weight=llm_weight
            )
            
            if not similar_docs:
                logger.warning("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
                return "æŠ±æ­‰ï¼Œæˆ‘åœ¨æ–‡æ¡£ä¸­æ²¡æœ‰æ‰¾åˆ°ä¸æ‚¨é—®é¢˜ç›¸å…³çš„ä¿¡æ¯ã€‚"
            
            # æ„å»ºä¸Šä¸‹æ–‡
            context_parts = []
            sources = []
            
            for i, doc in enumerate(similar_docs[:5]):  # åªä½¿ç”¨å‰5ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£
                context_parts.append(f"æ–‡æ¡£ç‰‡æ®µ {i+1}:\n{doc['text']}")
                sources.append(doc.get('document_name', 'æœªçŸ¥æ–‡æ¡£'))
            
            context = "\n\n".join(context_parts)
            sources_text = "ã€".join(list(set(sources)))
            
            # æ„å»ºç”¨æˆ·æç¤ºè¯
            user_prompt = f"""åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼Œè¯·å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š

æ–‡æ¡£å†…å®¹ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·æä¾›è¯¦ç»†çš„åˆ†æè¿‡ç¨‹å’Œå‡†ç¡®çš„ç­”æ¡ˆã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ã€‚

åœ¨å›ç­”æœ«å°¾è¯·æ ‡æ³¨ä¿¡æ¯æ¥æºçš„æ–‡æ¡£åç§°ï¼š{sources_text}"""

            # è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆ
            logger.info("æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...")
            response = self.ollama_client.chat(
                model='deepseek-r1:14b',
                messages=[
                    {"role": "system", "content": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆåŠ©æ‰‹ï¼Œä¸“é—¨å›ç­”åŸºäºä¸Šä¼ æ–‡æ¡£çš„é‡‘èç›¸å…³é—®é¢˜ã€‚

ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„æ–‡æ¡£å†…å®¹ï¼Œå‡†ç¡®å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚è¯·éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. **ä¸¥æ ¼åŸºäºæ–‡æ¡£å†…å®¹**ï¼šåªä½¿ç”¨æä¾›çš„æ–‡æ¡£å†…å®¹æ¥å›ç­”é—®é¢˜ï¼Œä¸è¦ä½¿ç”¨å¤–éƒ¨çŸ¥è¯†
2. **å‡†ç¡®å¼•ç”¨**ï¼šåœ¨å›ç­”ä¸­æ˜ç¡®æŒ‡å‡ºä¿¡æ¯æ¥æºçš„æ–‡æ¡£åç§°
3. **è¯¦ç»†åˆ†æ**ï¼šæä¾›è¯¦ç»†çš„åˆ†æè¿‡ç¨‹ï¼Œè§£é‡Šå¦‚ä½•ä»æ–‡æ¡£ä¸­å¾—å‡ºç­”æ¡ˆ
4. **è¯šå®å›ç­”**ï¼šå¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜"æ ¹æ®æä¾›çš„æ–‡æ¡£ï¼Œæ— æ³•æ‰¾åˆ°ç›¸å…³ä¿¡æ¯"
5. **ä¿æŒå®¢è§‚**ï¼šä¿æŒå®¢è§‚ä¸­ç«‹çš„åˆ†ææ€åº¦ï¼Œé¿å…ä¸»è§‚åˆ¤æ–­

è¯·ç¡®ä¿ä½ çš„å›ç­”å‡†ç¡®ã€è¯¦ç»†ä¸”åŸºäºæ–‡æ¡£å†…å®¹ã€‚"""},
                    {"role": "user", "content": user_prompt}
                ]
            )
            
            answer = response['message']['content']
            logger.info("ç­”æ¡ˆç”Ÿæˆå®Œæˆ")
            
            return answer
            
        except Exception as e:
            logger.error(f"å›ç­”é—®é¢˜æ—¶å‡ºé”™: {str(e)}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°äº†é”™è¯¯: {str(e)}"

    def clear_knowledge_base(self):
        """æ¸…ç©ºçŸ¥è¯†åº“"""
        logger.info("ğŸ—‘ï¸ å¼€å§‹æ¸…ç©ºçŸ¥è¯†åº“...")
        try:
            success = self.vector_store.clear_collection()
            if success:
                logger.info("âœ… çŸ¥è¯†åº“æ¸…ç©ºæˆåŠŸ")
                print_success("çŸ¥è¯†åº“æ¸…ç©ºæˆåŠŸ")
            else:
                logger.error("âŒ çŸ¥è¯†åº“æ¸…ç©ºå¤±è´¥")
                print_error("çŸ¥è¯†åº“æ¸…ç©ºå¤±è´¥")
            return success
        except Exception as e:
            logger.error(f"âŒ æ¸…ç©ºçŸ¥è¯†åº“æ—¶å‡ºé”™: {str(e)}")
            print_error(f"æ¸…ç©ºçŸ¥è¯†åº“æ—¶å‡ºé”™: {str(e)}")
            return False

    def get_agent_status(self) -> Dict[str, Any]:
        """è·å–æ™ºèƒ½ä½“ç³»ç»ŸçŠ¶æ€"""
        logger.info("ğŸ“Š è·å–æ™ºèƒ½ä½“ç³»ç»ŸçŠ¶æ€...")
        try:
            # è·å–å‘é‡å­˜å‚¨ç»Ÿè®¡
            collection_stats = self.vector_store.get_collection_stats()
            logger.info(f"ğŸ“ˆ å‘é‡å­˜å‚¨ç»Ÿè®¡: {collection_stats}")
            
            status = {
                "system_status": "running",
                "agents": [
                    {"name": "retrieval_agent", "status": "ready"},
                    {"name": "analysis_agent", "status": "ready"},
                    {"name": "answer_agent", "status": "ready"},
                    {"name": "coordinator", "status": "ready"}
                ],
                "total_agents": 4,
                "vector_store": collection_stats,
                "ollama_status": "connected"
            }
            
            logger.info("âœ… æ™ºèƒ½ä½“ç³»ç»ŸçŠ¶æ€è·å–æˆåŠŸ")
            return status
        except Exception as e:
            logger.error(f"âŒ è·å–æ™ºèƒ½ä½“ç³»ç»ŸçŠ¶æ€å¤±è´¥: {str(e)}")
            return {
                "system_status": "error",
                "error": str(e),
                "agents": [],
                "total_agents": 0
            }

def main():
    """ä¸»å‡½æ•°ï¼Œç”¨äºæµ‹è¯•"""
    logger.info("ğŸ§ª å¼€å§‹AutoGenç³»ç»Ÿæµ‹è¯•...")
    try:
        # åˆ›å»ºæ™ºèƒ½ä½“ç³»ç»Ÿ
        logger.info("ğŸš€ åˆ›å»ºAutoGenæ™ºèƒ½ä½“ç³»ç»Ÿ...")
        system = AutoGenRAGSystem()
        
        # æµ‹è¯•é—®ç­”
        question = "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"
        logger.info(f"ğŸ¤” æµ‹è¯•é—®é¢˜: {question}")
        answer = system.answer_question(question)
        print(f"é—®é¢˜: {question}")
        print(f"ç­”æ¡ˆ: {answer}")
        logger.info("âœ… æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        print_error(f"æµ‹è¯•å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main() 